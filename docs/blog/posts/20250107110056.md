---
comments: true
date: 2025-01-07
updated: 2025-01-07
title: Fine-Tuning GPT-4o-mini Model in Chat Text Completion Format
description: Learn how to fine-tune the GPT-4o-mini model for specific tasks using the chat-based text completion format. A step-by-step guide to prepare, format, and execute fine-tuning.
categories:
  - Machine Learning
tags:
  - GPT-4o-mini
  - Fine-Tuning
  - OpenAI
  - Machine Learning
  - AI Models
author: harmindersinghnijjar
---

Here’s a rewritten and streamlined guide based on your provided content:

---

# Fine-Tuning GPT-4o-mini: A Step-by-Step Guide

Fine-tuning GPT-4o-mini allows you to customize the model for tasks like writing proposals, generating summaries, or creating tailored AI responses. This guide breaks the process into two main steps: converting your data into a compatible format and executing the fine-tuning process.

---

## Step 1: Data Preparation

### Creating Your Dataset
Fine-tuning requires a `.jsonl` dataset where each line represents a structured chat interaction. For example:

```jsonl
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the capital of France?"}, {"role": "assistant", "content": "The capital of France is Paris."}]}
{"messages": [{"role": "system", "content": "You are a travel expert."}, {"role": "user", "content": "What are the best places to visit in Europe?"}, {"role": "assistant", "content": "Some of the best places to visit in Europe include Paris, Rome, Barcelona, and Amsterdam."}]}
```

### Automating Dataset Creation
Use the **Text to JSONL Converter** hosted on [Streamlit](https://fine-tune-4o-mini.streamlit.app/) to transform your `.txt` file into a `.jsonl` file.

#### Steps:
1. Write your stories in a `.txt` file. Each story should start with "Story X" (e.g., `Story 1`).
2. Visit the [Streamlit Text to JSONL Converter](https://fine-tune-4o-mini.streamlit.app/).
3. Upload your `.txt` file.
4. Preview random JSONL entries.
5. Download the processed `stories.jsonl` file.

---

### Sample Code for Custom Conversion (Optional)

If you'd like to perform the conversion locally, use this Python script:

```python
import json
import re

def clean_text(text):
    return re.sub(r"^\d+\s*\*?\s*", "", text).strip()

def convert_to_jsonl(file_content):
    stories = file_content.strip().split("Story ")
    jsonl_data = []
    for story in stories:
        if story.strip():
            question, _, response = story.partition("?")
            jsonl_data.append({
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": question.strip() + "?"},
                    {"role": "assistant", "content": response.strip()},
                ]
            })
    return jsonl_data

with open("stories.txt", "r") as f:
    data = f.read()

jsonl_output = convert_to_jsonl(data)

with open("stories.jsonl", "w") as f:
    for item in jsonl_output:
        f.write(json.dumps(item) + "\n")
```

---

## Step 2: Fine-Tuning the Model

Once your `.jsonl` file is ready, follow these steps:

### Uploading Your Dataset
Use OpenAI's API to upload the dataset for fine-tuning:

```python
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

# Upload training file
response = openai.File.create(
    file=open("stories.jsonl", "rb"),
    purpose="fine-tune"
)

training_file_id = response["id"]
print(f"File uploaded successfully. File ID: {training_file_id}")
```

### Starting the Fine-Tuning Job
Initiate the fine-tuning process:

```python
fine_tune_response = openai.FineTune.create(
    training_file=training_file_id,
    model="gpt-4o-mini"
)

print("Fine-tuning job created:")
print(fine_tune_response)
```

---

## Best Practices
1. **Dataset Quality**: Include diverse and well-structured examples.
2. **System Role**: Define clear instructions for the assistant’s behavior in the `system` message.
3. **Testing**: Use unseen test prompts to evaluate the fine-tuned model.
4. **Iteration**: Update your dataset based on test results and re-train if needed.

---

Fine-tuning GPT-4o-mini is a powerful way to create a personalized AI model tailored to your specific needs. By leveraging tools like the Streamlit app and OpenAI's API, the process becomes efficient and accessible. Happy fine-tuning!