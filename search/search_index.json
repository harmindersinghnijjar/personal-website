{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to my personal documentation site, a curated collection of notes, guides, and insights that I have found valuable. It is my hope that you will find these resources equally beneficial.  </p> <p>Please note that this site is a continuous work in progress, with new content regularly added and existing content frequently updated. The information provided is based on my personal experiences and perspectives, which may not align with every individual's circumstances. Your feedback and suggestions are always welcome, and I encourage you to share your thoughts.  </p>"},{"location":"#projects","title":"Projects","text":"<p>Each year, I will undertake a series of projects with defined deadlines. This site serves as a platform to document my progress, share insights, and reflect on the outcomes of these endeavors. If you are interested in collaborating on a project or have a project idea, please feel free to reach out on Discord.</p> <p>Upon completion, projects will be archived for future reference, so be sure to explore the archive section for a record of past work.  </p>"},{"location":"#blog","title":"Blog","text":"<p>The blog section features a variety of posts on topics that capture my interest. These include tutorials, guides, opinion pieces, and other content that I hope will provide value and inspiration.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/","title":"Transferring Files Between WSL and Windows","text":"","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#transferring-files-between-wsl-and-windows","title":"Transferring Files Between WSL and Windows","text":"<p>This guide provides a step-by-step approach to transferring files between Windows Subsystem for Linux (WSL) and Windows using tools like SCP (Secure Copy). It includes commands for file management and efficient navigation in both environments.</p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#logging-into-zomro-vps-using-wsl-in-ubuntu-cli","title":"Logging into Zomro VPS using WSL in Ubuntu CLI","text":"<p>To access your Zomro VPS using WSL\u2019s Ubuntu terminal:</p> <ol> <li>Open the Ubuntu terminal via the Windows Start menu.</li> <li>Use the <code>ssh</code> command to connect to your VPS:</li> </ol> <p><code>ssh your_username@your_server_ip</code></p> <p>Replace <code>your_username</code> with your VPS username and <code>your_server_ip</code> with the server\u2019s IP address.</p> <ol> <li>Enter your VPS password when prompted. After logging in, you can manage your VPS from the Ubuntu CLI.</li> </ol>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#locating-file-paths-in-ubuntu-cli","title":"Locating File Paths in Ubuntu CLI","text":"<p>Navigating and identifying file paths in Ubuntu is essential for transferring files. Use these commands for efficient file management:</p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#1-present-working-directory-pwd","title":"1. Present Working Directory (<code>pwd</code>)","text":"<p>Displays the absolute path of the current directory:</p> <p><code>pwd</code></p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#2-list-directory-contents-ls","title":"2. List Directory Contents (<code>ls</code>)","text":"<p>Shows files and directories in the current location:</p> <p><code>ls</code></p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#3-find-a-file-find","title":"3. Find a File (<code>find</code>)","text":"<p>Searches for a file in the system:</p> <p><code>find / -name example.txt</code></p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#4-change-directory-cd","title":"4. Change Directory (<code>cd</code>)","text":"<p>Navigates through directories:</p> <p><code>cd /path/to/directory</code></p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#5-access-windows-files","title":"5. Access Windows Files","text":"<p>WSL allows access to Windows files via <code>/mnt</code>. For example:</p> <p><code>cd /mnt/c/Users/YourUsername/Desktop</code></p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#file-transfer-methods-using-scp","title":"File Transfer Methods Using SCP","text":"","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#using-scp-secure-copy","title":"Using SCP (Secure Copy)","text":"<p>The <code>scp</code> command securely copies files between WSL and Windows.</p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#syntax","title":"Syntax","text":"<pre><code>scp username@source:/path/to/source/file /path/to/destination/\n</code></pre>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#example-copy-files-from-wsl-to-windows","title":"Example: Copy Files from WSL to Windows","text":"<p>To copy screenshots from a remote VPS to your Windows Desktop:</p> <pre><code>scp root@45.88.107.136:/root/zomro-selenium-base/screenshots/* \"/mnt/c/Users/Harminder Nijjar/Desktop/\"\n</code></pre> <p>This command transfers all files from the VPS directory to the specified Windows Desktop folder.</p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/21/transferring-files-between-wsl-and-windows/#conclusion","title":"Conclusion","text":"<p>Transferring files between WSL and Windows is simple and efficient using commands like <code>scp</code>. Mastering these techniques will streamline your workflow and enhance your productivity across WSL and Windows environments.</p>","tags":["WSL","Windows","Ubuntu","Linux","File Transfer","SCP","Secure Copy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/","title":"Transferring Script Files to Local System or VPS","text":"","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#transferring-script-files-to-local-system-or-vps","title":"Transferring Script Files to Local System or VPS","text":"<p>This guide explains the process of transferring a Python script for a Facebook Marketplace Scraper and setting it up on either a local system or a VPS. This scraper helps you collect and manage data from online listings efficiently.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#features-of-the-facebook-marketplace-scraper","title":"Features of the Facebook Marketplace Scraper","text":"<ul> <li>Data Storage: Uses SQLite for local storage and integration with Google Sheets for cloud-based storage.</li> <li>Notifications: Optional Telegram Bot integration for updates.</li> <li>Proxy Support: Includes compatibility with services like Smartproxy to manage requests.</li> </ul>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#local-system-setup-process-windows","title":"Local System Setup Process (Windows)","text":"<p>This section outlines the steps to set up the scraper on your local machine.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have:</p> <ul> <li>Python 3.6 or higher installed.</li> <li>Access to Google Cloud with credentials for Google Sheets API.</li> <li>An SQLite-supported system.</li> <li>A Telegram bot token (optional).</li> <li>Dependencies listed in the <code>requirements.txt</code>.</li> </ul>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#setup-steps","title":"Setup Steps","text":"","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-1-obtain-script-files","title":"Step 1: Obtain Script Files","text":"<ul> <li>Download the script files (typically a ZIP archive) and extract them.</li> <li>Ensure the following files are present:</li> <li><code>fb_parser.py</code>: The main script.</li> <li><code>requirements.txt</code>: Python dependencies.</li> </ul>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-2-install-dependencies","title":"Step 2: Install Dependencies","text":"<p>Open a terminal, navigate to the script folder, and run:</p> <pre><code>pip install -r requirements.txt\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-3-configure-google-sheets-api","title":"Step 3: Configure Google Sheets API","text":"<ol> <li>Create a Google Cloud project and enable the Sheets API.</li> <li>Download the <code>credentials.json</code> file and place it in the script folder.</li> </ol>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-4-initialize-the-database","title":"Step 4: Initialize the Database","text":"<p>Run the following command to create the SQLite database:</p> <pre><code>python fb_parser.py --initdb\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-5-configure-telegram-notifications-optional","title":"Step 5: Configure Telegram Notifications (Optional)","text":"<p>Edit <code>fb_parser.py</code> and add your <code>bot_token</code> and <code>bot_chat_id</code>.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-6-run-the-scraper","title":"Step 6: Run the Scraper","text":"<p>Start the scraper with:</p> <pre><code>python fb_parser.py\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-7-automation-optional","title":"Step 7: Automation (Optional)","text":"<p>Use Task Scheduler to automate script execution.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#vps-setup-process","title":"VPS Setup Process","text":"","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#vps-requirements","title":"VPS Requirements","text":"<ul> <li>VPS with SSH access and Python 3.6+ installed.</li> <li>Linux OS (Ubuntu or CentOS preferred).</li> <li>Necessary script files and dependencies.</li> </ul>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#setup-steps_1","title":"Setup Steps","text":"","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-1-log-in-to-vps","title":"Step 1: Log in to VPS","text":"<p>Access your VPS via SSH:</p> <pre><code>ssh username@hostname\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-2-transfer-script-files","title":"Step 2: Transfer Script Files","text":"<p>Upload files using SCP or SFTP:</p> <pre><code>scp fb_parser.py requirements.txt username@hostname:/path/to/directory\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-3-install-python-and-dependencies","title":"Step 3: Install Python and Dependencies","text":"<p>Update your system and install Python dependencies:</p> <pre><code>sudo apt update\nsudo apt install python3-pip\npip3 install -r requirements.txt\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-4-configure-credentials","title":"Step 4: Configure Credentials","text":"<p>Follow the same steps as the local setup to configure Google Sheets and Telegram credentials.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-5-run-the-scraper","title":"Step 5: Run the Scraper","text":"<p>Navigate to the script directory and execute:</p> <pre><code>python3 fb_parser.py\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#step-6-automate-with-cron","title":"Step 6: Automate with Cron","text":"<p>Use <code>cron</code> to schedule periodic script execution:</p> <pre><code>crontab -e\n# Add the line below to run daily at midnight\n0 0 * * * python3 /path/to/fb_parser.py\n</code></pre>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#conclusion","title":"Conclusion","text":"<p>By following this guide, you can effectively transfer and set up the Facebook Marketplace Scraper on your local system or VPS. This tool simplifies the process of collecting and managing online listing data.</p>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2023/11/27/transferring-script-files-to-local-system-or-vps/#references","title":"References","text":"<ul> <li>Google Sheets API</li> <li>SQLite</li> <li>Telegram Bot API</li> <li>Smartproxy</li> </ul>","tags":["Facebook Marketplace Scraper","Python","SQLite","Google Sheets API","Telegram Bot API","Smartproxy"]},{"location":"blog/2024/11/24/my-first-blog-post/","title":"My First Blog Post","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>"},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/","title":"Using Crosshair.AHK to Assist with Aiming on Xbox Cloud Gaming","text":"","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/#using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming","title":"Using Crosshair.AHK to Assist with Aiming on Xbox Cloud Gaming","text":"<p>I recently started playing games on Xbox Cloud Gaming on PC, and I noticed that the aim assist with reWASD wasn't as powerful as I had initially expected. I decided to use Crosshair.AHK to help me aim better. Crosshair.AHK is a simple script that displays a crosshair on your screen to help you aim better in games. In this post, I will show you how to use Crosshair.AHK to assist with aiming in Fortnite on Xbox Cloud Gaming.</p>","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/#features-of-crosshairahk","title":"Features of Crosshair.AHK","text":"<p>Crosshair.AHK has several features that make it a great tool for improving your aim in games. Some of the key features include:</p> <ul> <li>10 different crosshair styles</li> <li>Customizable crosshair colors</li> <li>Fullscreen crosshair support</li> </ul>","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/#crosshair-styles","title":"Crosshair Styles","text":"<p>Crosshair.AHK offers 10 different crosshair styles to choose from, allowing you to find the one that works best for you. The crosshair styles range from simple dots to more complex designs, giving you plenty of options to customize your crosshair to your liking. Crosshair styles can be easily changed by pressing the <code>F10</code> key.</p>","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/#customizable-crosshair-colors","title":"Customizable Crosshair Colors","text":"<p>Crosshair.AHK allows you to customize the color of your crosshair to suit your preferences. You can choose from a wide range of colors to find the one that stands out the most against your game's background. Crosshair colors can be easily changed by pressing the <code>F10</code> key and using the color change widget to select the desired color.</p>","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/24/using-crosshairahk-to-assist-with-aiming-on-xbox-cloud-gaming/#fullscreen-crosshair-support","title":"Fullscreen Crosshair Support","text":"<p>Crosshair.AHK supports fullscreen mode, allowing you to use the crosshair in games that run in fullscreen. This feature is particularly useful for games that don't have built-in crosshairs or where the crosshair is difficult to see against the game's background. To enable fullscreen mode, simply press the <code>F11</code> key.</p>","tags":["Xbox Cloud Gaming","AHK","reWASD","Fortnite","Aim Assist","Aiming","Gaming Tools"]},{"location":"blog/2024/11/25/harminder-singh-nijjars-digital-art-catalog/","title":"Harminder Singh Nijjar's Digital Art Catalog","text":"<p>2024-11-25: While sitting on the dining table drinking a Celsius Peach Vibe, I decided to create a quick digital drawing of the can next to a container of JIF peanut butter. The drawing was done on my MobiScribe WAVE using the stylus that came with the device. The MobiScribe WAVE is a great tool for digital art, and I enjoy using it for quick sketches and drawings. </p> <p>2024-11-26 20:17: Today I drew a quick sketch of two wolf pups howling at the moon. </p>","tags":["Drawing","Digital Art"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/","title":"Agentic Web Scraping in 2024","text":"<p>Web scraping best practices have evolved significantly in the past couple of years, with the rise of agentic web scraping marking a new era in data collection and analysis. In this post, we'll explore the concept of agentic web scraping, its benefits, and how it is transforming the landscape of data-driven decision-making.</p>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/#evolution-of-web-scraping","title":"Evolution of Web Scraping","text":"<p>Typically, web scraping involved extracting data from websites by mimiking browser behaviour through HTTP requests and web automation frameworks like Selenium, Puppeteer, or Playwright. This process required developers to write specific code for each website, making it time-consuming, error-prone, and susceptible to changes in website structure. So much so that 50% to 70% of engineering resources in data aggregation teams were spent on scraping stystems early on. However, with the advent of agentic web scraping, this approach has been revolutionized. LLMs are able to make sense of any data thrown at them, allowing them to understand large amounts of raw HTML and make decisions based on it.</p> <p>This comes with a drawback, however. The more unstructured data you throw at an LLM, the more likely it is to make mistakes and the more tokens are consumed. This is why it's important to have as close to structured, human-readable data as possible.</p>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/#structuring-data-for-agentic-web-scraping","title":"Structuring Data for Agentic Web Scraping","text":"<p>In order to be able to use LLM Scraper Agents and Reasoning Agents, we need to convert raw HTML data into a more structured format. Markdown is a great choice for this, as it is human-readable and easily parsed by LLMs. After converting scraped data into structured markdown, we can feed it into LLM Scraper Agents and Reasoning Agents to make sense of it and extract insights.</p>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/#web-scraper-agents-for-public-data","title":"Web Scraper Agents for Public Data","text":"<p>Public data is data that is freely available on the web, such as news articles, blog posts, and product descriptions. This data can be scraped and used for various purposes and does not require any special permissions such as bypassing CAPTCHAs or logging in.</p> <p>Some APIs that can be used to convert raw HTML data into structured markdown include:</p> <p>Firecrawl</p> <p>Firecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API </p> <p>Output: Good quality markdown with most hyperlinks preserved</p> <p>Rate limit: 1000 requests per minute</p> <p>Cost: $0.06 per 100 pages</p> <p>Jina</p> <p>Turn a website into a structured data by adding r.jina.ai in front of the URL.</p> <p>Output: Focuses primarily on extracting content rather than preserving hyperlinks</p> <p>Rate limit: 1000 requests per minute</p> <p>Cost: Free</p> <p>Spider Cloud</p> <p>Spider is a leading web crawling tool designed for speed and cost-effectiveness, supporting various data formats including LLM-ready markdown.</p> <p>Output: Happy medium between Firecrawl and Jina with good quality markdown</p> <p>Rate limit: 50000 requests per minute</p> <p>Cost: $0.03 per 100 pages</p>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/#web-scraper-agents-for-private-data","title":"Web Scraper Agents for Private Data","text":"<p>As mentioned earlier, web automation frameworks like Selenium, Puppeteer, or Playwright are used to scrape private data that requires interaction to access restricted areas of a website. These tools can now be used to build agentic web scraping systems that can understand and reason about the data they collect. However, the issue with these tools is determining which UI elements to interact with to access the abovementioned restricted areas of a site. This is where AgentQL comes in.</p> <p>AgentQL</p> <p>AgentQL allows web automation frameworks to accurately navigate websites, even when the website structure changes.</p> <p>Rate limit: 10 API calls per minute</p> <p>Cost: $0.02 per API call</p> <p>Using AgentQL in conjunction with web automation frameworks enables developers to build agentic web scraping systems that can access and reason about private data, making the process more efficient and reliable.</p> <p></p> <p>Some examples of actions we're able to perform with AgentQL along with Playwright or Selenium include:</p> <ul> <li>Save and load authenticated state</li> <li>Wait for a page to load</li> <li>Close a cookie dialog</li> <li>Close popup windows</li> <li>Compare product prices across multiple websites</li> </ul>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/11/25/agentic-web-scraping-in-2024/#conclusion","title":"Conclusion","text":"<p>Agentic web scraping is transforming the way data is collected and analyzed, enabling developers to build systems that can understand and reason about the data they collect. By structuring data in a human-readable format like markdown and using tools like LLM Scraper Agents, Reasoning Agents, and AgentQL, developers can create efficient and reliable web scraping systems that can access both public and private data. This new approach to web scraping is revolutionizing the field of data-driven decision-making and opening up new possibilities for data analysis and insights.</p>","tags":["Web Scraping","Agentic Web Scraping","Data Collection","Data Analysis"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/","title":"Building an Agentic Web Scraping Pipeline for Crypto and Meme Coins","text":"","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#how-to-build-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins","title":"How to Build an Agentic Web Scraping Pipeline for Crypto and Meme Coins","text":"<p>Agentic web scraping revolutionizes data collection by leveraging advanced scraping tools and LLM-based reasoning to analyze websites for actionable insights. This guide demonstrates how to build a closed-loop pipeline for analyzing popular crypto and meme coin websites to enhance trading strategies.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#websites-to-scrape","title":"Websites to Scrape","text":"<p>The following websites will serve as data inputs for the pipeline:</p> <ol> <li> <p>Movement Market    Facilitates buying and selling meme coins with email and credit card integration.</p> </li> <li> <p>Raydium    A decentralized exchange for trading tokens and coins.</p> </li> <li> <p>Jupiter    A platform for seamless token swaps.</p> </li> <li> <p>Rugcheck    A tool for evaluating meme coins and identifying scams.</p> </li> <li> <p>Photon Sol    A browser-based solution for trading low-cap coins.</p> </li> <li> <p>Cielo Finance    Offers a copy-trading platform to follow top-performing wallets.</p> </li> </ol>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#step-1-structuring-data-for-public-websites","title":"Step 1: Structuring Data for Public Websites","text":"<p>For effective analysis, raw HTML data from these websites must be structured into human-readable Markdown.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#tool-firecrawl","title":"Tool: Firecrawl","text":"<p>Use Firecrawl to scrape and format the websites:</p> <p>Example: Scraping Movement Market <pre><code>import requests\n\nFIRECRAWL_API = \"https://api.firecrawl.com/v1/scrape\"\nAPI_KEY = \"your_firecrawl_api_key\"\n\ndef scrape_with_firecrawl(url):\n    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n    data = {\"url\": url, \"output\": \"markdown\"}\n    response = requests.post(FIRECRAWL_API, json=data, headers=headers)\n\n    if response.status_code == 200:\n        return response.json().get(\"markdown\")\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None\n\nmarkdown_data = scrape_with_firecrawl(\"https://movement.market/\")\nprint(markdown_data)\n</code></pre></p> <p>Repeat the process for all listed websites to create structured Markdown files.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#step-2-analyze-public-data-with-reasoning-agents","title":"Step 2: Analyze Public Data with Reasoning Agents","text":"<p>Once the data is structured, LLMs can be used to analyze trends, extract features, and provide actionable insights.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#example-analyzing-data-with-openai-api","title":"Example: Analyzing Data with OpenAI API","text":"<pre><code>import openai\n\nopenai.api_key = \"your_openai_api_key\"\n\ndef analyze_markdown(markdown_data):\n    response = openai.Completion.create(\n        model=\"text-davinci-003\",\n        prompt=f\"Analyze this Markdown data to identify trading opportunities and community sentiment:\\n\\n{markdown_data}\",\n        max_tokens=1000\n    )\n    return response.choices[0].text.strip()\n\nmarkdown_example = \"# Example Markdown\\nThis is an example of markdown content for analysis.\"\nanalysis = analyze_markdown(markdown_example)\nprint(analysis)\n</code></pre>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#step-3-scraping-private-data-with-web-automation","title":"Step 3: Scraping Private Data with Web Automation","text":"<p>For websites requiring interaction (e.g., logins or dynamic content), use Python's Playwright library with AgentQL for advanced navigation and data extraction.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#example-scraping-photon-sol-with-playwright-and-agentql","title":"Example: Scraping Photon Sol with Playwright and AgentQL","text":"<p>Install Playwright and AgentQL: <pre><code>pip install playwright\nplaywright install\n</code></pre></p> <p>Write the Python Script: <pre><code>from playwright.sync_api import sync_playwright\n\ndef scrape_photon_sol():\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n\n        # Navigate to Photon Sol\n        page.goto(\"https://photon-sol.tinyastro.io/\")\n\n        # Simulate interactions if needed\n        page.wait_for_timeout(3000)  # Wait for the page to load completely\n        content = page.content()\n\n        print(content)  # Print or save the page content\n        browser.close()\n\nscrape_photon_sol()\n</code></pre></p> <p>This approach ensures data can be extracted even from dynamic websites.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#step-4-automating-the-pipeline","title":"Step 4: Automating the Pipeline","text":"<p>Use Python-based automation tools like Apache Airflow to schedule and run the scraping and analysis pipeline.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#example-airflow-configuration-for-the-pipeline","title":"Example: Airflow Configuration for the Pipeline","text":"<pre><code>from airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom datetime import datetime\n\ndef scrape():\n    # Add scraping logic for all websites here\n    print(\"Scraping data...\")\n\ndef analyze():\n    # Add analysis logic here\n    print(\"Analyzing data...\")\n\nwith DAG('crypto_pipeline', start_date=datetime(2024, 11, 25), schedule_interval='@daily') as dag:\n    scrape_task = PythonOperator(task_id='scrape', python_callable=scrape)\n    analyze_task = PythonOperator(task_id='analyze', python_callable=analyze)\n\n    scrape_task &gt;&gt; analyze_task\n</code></pre>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#insights-from-websites","title":"Insights from Websites","text":"<p>Here's what you can focus on while analyzing the scraped data:</p> <ol> <li>Movement Market: Review ease of use, transaction speed, and user feedback.</li> <li>Raydium: Analyze liquidity and trading fees for tokens.</li> <li>Jupiter: Evaluate swap rates and platform efficiency.</li> <li>Rugcheck: Identify red flags in meme coin projects to avoid scams.</li> <li>Photon Sol: Assess platform usability for low-cap token trading.</li> <li>Cielo Finance: Analyze wallet strategies and portfolio performance.</li> </ol>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#step-5-closing-the-loop","title":"Step 5: Closing the Loop","text":"<p>To maintain a closed-loop pipeline, configure the workflow to automatically re-scrape websites at regular intervals and update analyses with new data. This ensures decisions are based on the latest information.</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/building-an-agentic-web-scraping-pipeline-for-crypto-and-meme-coins/#conclusion","title":"Conclusion","text":"<p>By integrating structured scraping, advanced analysis, and automation, this agentic pipeline enables real-time insights into the crypto and meme coin ecosystem. Use the steps outlined above to stay ahead in the volatile world of meme coins while minimizing risks and maximizing returns. \ud83d\ude80</p>","tags":["Web Scraping","Crypto","Meme Coins","Agentic Web Scraping","LLM","Data Analysis","Automation","Python","Playwright"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/","title":"Installing ROS 1 on Raspberry Pi","text":"","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#installing-ros-1-on-raspberry-pi","title":"Installing ROS 1 on Raspberry Pi","text":"<p>Robot Operating System (ROS) is an open-source framework widely used for robotic applications. This guide walks you through installing ROS 1 (Noetic) on a Raspberry Pi running Ubuntu. ROS 1 Noetic is the recommended version for Raspberry Pi and supports Ubuntu 20.04.</p>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have the following:</p> <ul> <li>Raspberry Pi 4 or later with at least 4GB of RAM (8GB is recommended for larger projects).</li> <li>Ubuntu 20.04 installed on the Raspberry Pi (Desktop or Server version).</li> <li>Internet connection for downloading and installing packages.</li> </ul>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-1-set-up-your-raspberry-pi","title":"Step 1: Set Up Your Raspberry Pi","text":"<ol> <li>Update and Upgrade System Packages:    <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre></li> <li>Install Required Dependencies:    <pre><code>sudo apt install -y curl gnupg2 lsb-release\n</code></pre></li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-2-configure-ros-repositories","title":"Step 2: Configure ROS Repositories","text":"<ol> <li> <p>Add the ROS Repository Key:    <pre><code>sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -\n</code></pre></p> </li> <li> <p>Add the ROS Noetic Repository:    <pre><code>echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" | sudo tee /etc/apt/sources.list.d/ros-latest.list\n</code></pre></p> </li> <li> <p>Update Package List:    <pre><code>sudo apt update\n</code></pre></p> </li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-3-install-ros-1-noetic","title":"Step 3: Install ROS 1 Noetic","text":"<ol> <li> <p>Install the Full ROS Desktop Version:    <pre><code>sudo apt install -y ros-noetic-desktop-full\n</code></pre></p> </li> <li> <p>Verify the Installation:    Check the installed ROS version:    <pre><code>rosversion -d\n</code></pre>    This should return <code>noetic</code>.</p> </li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-4-initialize-ros-environment","title":"Step 4: Initialize ROS Environment","text":"<ol> <li> <p>Set Up ROS Environment Variables:    <pre><code>echo \"source /opt/ros/noetic/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> </li> <li> <p>Install rosdep:    rosdep is a dependency management tool for ROS:    <pre><code>sudo apt install -y python3-rosdep\n</code></pre></p> </li> <li> <p>Initialize rosdep:    <pre><code>sudo rosdep init\nrosdep update\n</code></pre></p> </li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-5-test-the-ros-installation","title":"Step 5: Test the ROS Installation","text":"<ol> <li> <p>Run roscore:    Start the ROS master process:    <pre><code>roscore\n</code></pre>    Leave this terminal open.</p> </li> <li> <p>Open a New Terminal and Run turtlesim:    Launch a simple simulation:    <pre><code>rosrun turtlesim turtlesim_node\n</code></pre></p> </li> <li> <p>Move the Turtle:    Open another terminal and control the turtle using:    <pre><code>rosrun turtlesim turtle_teleop_key\n</code></pre>    Use the arrow keys to move the turtle in the simulation.</p> </li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#step-6-install-additional-ros-tools","title":"Step 6: Install Additional ROS Tools","text":"<p>To enhance your ROS setup, install the following:</p> <ol> <li> <p>catkin Tools:    <pre><code>sudo apt install -y python3-catkin-tools\n</code></pre></p> </li> <li> <p>Common ROS Packages:    <pre><code>sudo apt install -y ros-noetic-rviz ros-noetic-rqt ros-noetic-rqt-common-plugins\n</code></pre></p> </li> <li> <p>GPIO and Hardware Libraries (for Pi-specific projects):    <pre><code>sudo apt install -y wiringpi pigpio\n</code></pre></p> </li> </ol>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>Issue: <code>rosdep</code> not initializing properly. Fix: Ensure network connectivity and retry:   <pre><code>sudo rosdep init\nrosdep update\n</code></pre></p> </li> <li> <p>Issue: ROS environment variables not set. Fix: Manually source the ROS setup file:   <pre><code>source /opt/ros/noetic/setup.bash\n</code></pre></p> </li> </ul>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2024/12/15/installing-ros-1-on-raspberry-pi/#conclusion","title":"Conclusion","text":"<p>Your Raspberry Pi is now configured with ROS 1 Noetic, ready for robotic projects. With this setup, you can develop and deploy various ROS packages, integrate hardware, and experiment with advanced robotic systems.</p> <p>Happy building!</p>","tags":["ROS","Raspberry Pi","Linux","Robotics"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/","title":"Setting Up Venom for WhatsApp Translation","text":"<p>Automating WhatsApp messaging can be a powerful tool for customer service, personal projects, or language translation. Using Venom and Google Translate, this guide will show you how to build a script that translates incoming Spanish messages to English and replies in Spanish.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#why-use-venom","title":"Why Use Venom?","text":"<p>Venom is a robust Node.js library that allows you to interact with WhatsApp Web. It\u2019s perfect for creating bots, automating tasks, or building translation systems like the one we\u2019ll create here.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#prerequisites","title":"Prerequisites","text":"<p>Before diving in, ensure you have the following installed:</p> <ol> <li>Node.js: Install from Node.js Official Website.</li> <li>npm or yarn: Installed alongside Node.js.</li> <li>Google Translate Library: For text translation.</li> <li>Venom: For WhatsApp automation.</li> </ol>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#install-required-packages","title":"Install Required Packages","text":"<p>Run the following commands to install the required libraries:</p> <pre><code>npm install venom-bot translate-google crypto\n</code></pre>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#implementation","title":"Implementation","text":"<p>Here\u2019s how to set up and use Venom to translate WhatsApp messages:</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#1-initialize-the-project","title":"1. Initialize the Project","text":"<p>Create a new file named <code>spanish_to_english.js</code> and start with the following boilerplate:</p> <pre><code>const venom = require('venom-bot');\nconst translate = require('translate-google');\nconst crypto = require('crypto');\n</code></pre>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#2-set-up-your-whatsapp-contact","title":"2. Set Up Your WhatsApp Contact","text":"<p>Replace the example WhatsApp contact ID with your own:</p> <pre><code>const TARGET_CONTACT_ID = 'your_number@c.us';\n</code></pre> <p>Find the contact ID by observing your logs while running Venom.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#3-implement-message-processing-logic","title":"3. Implement Message Processing Logic","text":"<p>Here\u2019s the full script for translating messages and avoiding duplicates using a hash and boolean:</p> <pre><code>// Keep track of message hashes to prevent reprocessing\nconst sentMessageHashes = new Set();\nlet isProcessing = false;\n\n// Start Venom session\nvenom\n  .create({\n    session: 'my-whatsapp-session',\n    multidevice: true,\n  })\n  .then((client) =&gt; start(client))\n  .catch((err) =&gt; console.error('Error starting Venom:', err));\n\nfunction start(client) {\n  console.log(`Listening for messages with contact ${TARGET_CONTACT_ID}`);\n\n  // Delay function to slow down processing\n  const delay = (ms) =&gt; new Promise((resolve) =&gt; setTimeout(resolve, ms));\n\n  // Hashing function to track processed messages\n  const generateHash = (messageBody) =&gt; crypto.createHash('sha256').update(messageBody).digest('hex');\n\n  // Handle incoming messages\n  client.onMessage(async (message) =&gt; {\n    if (message.from === TARGET_CONTACT_ID &amp;&amp; !message.fromMe) {\n      console.log('Received message from user:', message.body);\n\n      try {\n        // Translate from Spanish to English\n        const english = await translate(message.body, { to: 'en' });\n        console.log(`(Spanish \u2192 English): ${english}`);\n\n        // Reply in Spanish\n        const response = `Entendido: \"${english}\". \u00bfHay algo m\u00e1s en lo que pueda ayudarte?`;\n        await client.sendText(TARGET_CONTACT_ID, response);\n        console.log('Replied to the user in Spanish.');\n      } catch (error) {\n        console.error('Error translating incoming message:', error);\n      }\n    }\n  });\n\n  // Handle outgoing messages\n  client.onAnyMessage(async (message) =&gt; {\n    if (message.to === TARGET_CONTACT_ID &amp;&amp; message.fromMe &amp;&amp; !message.isGroupMsg) {\n      if (isProcessing) {\n        console.log('A message is already being processed. Skipping this message.');\n        return;\n      }\n\n      const messageHash = generateHash(message.body);\n\n      if (sentMessageHashes.has(messageHash)) {\n        console.log(`Skipping already handled outgoing message: Hash=${messageHash}`);\n        return;\n      }\n\n      isProcessing = true;\n\n      try {\n        console.log('Preparing to send message:', message.body);\n\n        // Translate to Spanish\n        const spanish = await translate(message.body, { to: 'es' });\n\n        sentMessageHashes.add(messageHash);\n\n        await delay(1000);\n\n        console.log(`(English \u2192 Spanish): ${spanish}`);\n        await client.sendText(TARGET_CONTACT_ID, spanish);\n\n        console.log(`Sent translated message: \"${spanish}\"`);\n      } catch (error) {\n        console.error('Error processing the message:', error);\n        sentMessageHashes.delete(messageHash);\n      } finally {\n        isProcessing = false;\n      }\n    }\n  });\n}\n</code></pre>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#4-replace-placeholder-values","title":"4. Replace Placeholder Values","text":"<p>Replace <code>your_number@c.us</code> in the <code>TARGET_CONTACT_ID</code> variable with the actual contact ID of the target WhatsApp user.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#5-run-the-script","title":"5. Run the Script","text":"<p>Run the script with:</p> <pre><code>node spanish_to_english.js\n</code></pre> <p>When a message is received: - Incoming Spanish messages are translated to English. - The bot replies in Spanish.</p> <p>For outgoing messages: - The bot translates English to Spanish and sends the translated message.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#debugging-tips","title":"Debugging Tips","text":"<ol> <li>Check Logs: Use <code>console.log</code> statements to debug message handling.</li> <li>Verify Contact ID: Ensure <code>TARGET_CONTACT_ID</code> matches the intended WhatsApp contact.</li> <li>Resolve Dependencies: Reinstall missing packages with <code>npm install</code>.</li> </ol>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/2025/01/05/setting-up-venom-for-whatsapp-translation/#conclusion","title":"Conclusion","text":"<p>This script demonstrates how to build a simple yet powerful WhatsApp bot using Venom and Google Translate. It ensures smooth, non-repetitive communication by managing a hash set of processed messages and using a boolean flag for sequential message processing. With this foundation, you can extend functionality to include more advanced translations, AI integrations, or chatbot capabilities.</p>","tags":["Node.js","Venom","WhatsApp Automation","Translation","JavaScript"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/programming/","title":"Programming","text":""},{"location":"blog/category/robotics/","title":"Robotics","text":""},{"location":"blog/category/art/","title":"Art","text":""},{"location":"blog/category/gaming/","title":"Gaming","text":""}]}